Node:
(type) c
(layer)0
	Element:body
						Node:
						(type) h2
						(layer)2
							Element:h2
							Element:a
								Pattern Tokenizer
							Element:a
								edit
						Node:
						(type) c
						(layer)2
							Element:p
								The
							Element:code
								pattern
								tokenizer uses a regular expression to either split text into terms whenever it matches a word separator, or to capture matching text as terms.
						Node:
						(type) c
						(layer)2
							Element:p
								The default pattern is
							Element:code
								\W+
								, which splits text whenever it encounters non-word characters.
						Node:
						(type) c
						(layer)2
							Element:img
						Node:
						(type) c
						(layer)2
									Node:
									(type) c
									(layer)3
										Element:h3
											Beware of Pathological Regular Expressions
									Node:
									(type) c
									(layer)3
										Element:p
											The pattern tokenizer uses
										Element:a
											Java Regular Expressions
											.
									Node:
									(type) c
									(layer)3
										Element:p
											A badly written regular expression could run very slowly or even throw a StackOverflowError and cause the node it is running on to exit suddenly.
									Node:
									(type) c
									(layer)3
										Element:p
											Read more about
										Element:a
											pathological regular expressions and how to avoid them
											.
						Node:
						(type) c
						(layer)2
									Node:
									(type) c
									(layer)3
										Element:h3
										Element:a
											Example output
										Element:a
											edit
									Node:
									(type) c
									(layer)3
										Element:pre
											POST _analyze { "tokenizer": "pattern", "text": "The foo_bar_size's default is 5." }
									Node:
									(type) c
									(layer)3
										Element:p
											The above sentence would produce the following terms:
									Node:
									(type) c
									(layer)3
										Element:pre
											[ The, foo_bar_size, s, default, is, 5 ]
						Node:
						(type) c
						(layer)2
									Node:
									(type) c
									(layer)3
										Element:h3
										Element:a
											Configuration
										Element:a
											edit
									Node:
									(type) c
									(layer)3
										Element:p
											The
										Element:code
											pattern
											tokenizer accepts the following parameters:
									Node:
									(type) c
									(layer)3
										Element:table
										Element:colgroup
										Element:col
										Element:col
										Element:tbody
										Element:tr
										Element:td
										Element:p
										Element:code
											pattern
										Element:td
										Element:p
											A
										Element:a
											Java regular expression
											, defaults to
										Element:code
											\W+
											.
										Element:tr
										Element:td
										Element:p
										Element:code
											flags
										Element:td
										Element:p
											Java regular expression
										Element:a
											flags
											. lags should be pipe-separated, eg
										Element:code
											"CASE_INSENSITIVE|COMMENTS"
											.
										Element:tr
										Element:td
										Element:p
										Element:code
											group
										Element:td
										Element:p
											Which capture group to extract as tokens. Defaults to
										Element:code
											-1
											(split).
						Node:
						(type) c
						(layer)2
									Node:
									(type) c
									(layer)3
										Element:h3
										Element:a
											Example configuration
										Element:a
											edit
									Node:
									(type) c
									(layer)3
										Element:p
											In this example, we configure the
										Element:code
											pattern
											tokenizer to break text into tokens when it encounters commas:
									Node:
									(type) c
									(layer)3
										Element:pre
											PUT my_index { "settings": { "analysis": { "analyzer": { "my_analyzer": { "tokenizer": "my_tokenizer" } }, "tokenizer": { "my_tokenizer": { "type": "pattern", "pattern": "," } } } } } POST my_index/_analyze { "analyzer": "my_analyzer", "text": "comma,separated,values" }
									Node:
									(type) c
									(layer)3
										Element:p
											The above example produces the following terms:
									Node:
									(type) c
									(layer)3
										Element:pre
											[ comma, separated, values ]
									Node:
									(type) c
									(layer)3
										Element:p
											In the next example, we configure the
										Element:code
											pattern
											tokenizer to capture values enclosed in double quotes (ignoring embedded escaped quotes
										Element:code
											\"
											). The regex itself looks like this:
									Node:
									(type) c
									(layer)3
										Element:pre
											"((?:\\"|[^"]|\\")*)"
									Node:
									(type) c
									(layer)3
										Element:p
											And reads as follows:
									Node:
									(type) c
									(layer)3
										Element:ul
										Element:li
											A literal
										Element:code
											"
										Element:li
										Element:p
											Start capturing:
										Element:ul
										Element:li
											A literal
										Element:code
											\"
											OR any character except
										Element:code
											"
										Element:li
											Repeat until no more characters match
										Element:li
											A literal closing
										Element:code
											"
									Node:
									(type) c
									(layer)3
										Element:p
											When the pattern is specified in JSON, the
										Element:code
											"
											and
										Element:code
											\
											characters need to be escaped, so the pattern ends up looking like:
									Node:
									(type) c
									(layer)3
										Element:pre
											\"((?:\\\\\"|[^\"]|\\\\\")+)\"
									Node:
									(type) c
									(layer)3
										Element:pre
											PUT my_index { "settings": { "analysis": { "analyzer": { "my_analyzer": { "tokenizer": "my_tokenizer" } }, "tokenizer": { "my_tokenizer": { "type": "pattern", "pattern": "\"((?:\\\\\"|[^\"]|\\\\\")+)\"", "group": 1 } } } } } POST my_index/_analyze { "analyzer": "my_analyzer", "text": "\"value\", \"value with embedded \\\" quote\"" }
									Node:
									(type) c
									(layer)3
										Element:p
											The above example produces the following two terms:
									Node:
									(type) c
									(layer)3
										Element:pre
											[ value, value with embedded \" quote ]
									Node:
									(type) c
									(layer)3
										Element:span
										Element:a
											« Keyword Tokenizer
									Node:
									(type) c
									(layer)3
										Element:span
										Element:a
											Path Hierarchy Tokenizer »
						Node:
						(type) c
						(layer)2
									Node:
									(type) c
									(layer)3
										Element:h3
											Top Videos
									Node:
									(type) c
									(layer)3
										Element:ul
										Element:li
										Element:a
											Elasticsearch Demo
										Element:li
										Element:a
											Kibana 101
										Element:li
										Element:a
											Logstash Primer
									Node:
									(type) c
									(layer)3
															Node:
															(type) c
															(layer)5
																Element:h5
																	Be in the know with the latest and greatest from Elastic.
															Node:
															(type) c
															(layer)5
																Element:p
																	Thanks for subscribing! We'll keep you updated with new releases.
						Node:
						(type) c
						(layer)2
									Node:
									(type) c
									(layer)3
										Element:footer
										Element:h3
										Element:a
											Products >
										Element:ul
										Element:li
										Element:a
											Elasticsearch
										Element:li
										Element:a
											Kibana
										Element:li
										Element:a
											Beats
										Element:li
										Element:a
											Logstash
										Element:li
										Element:a
											X-Pack
										Element:li
										Element:a
											Elastic Cloud
										Element:li
										Element:a
											Security (formerly Shield)
										Element:li
										Element:a
											Alerting (via Watcher)
										Element:li
										Element:a
											Monitoring (formerly Marvel)
										Element:li
										Element:a
											Graph
										Element:li
										Element:a
											Reporting
										Element:li
										Element:a
											Machine Learning
										Element:li
										Element:a
											ES-Hadoop
										Element:h3
											Resources
										Element:ul
										Element:li
										Element:a
											Blog
										Element:li
										Element:a
											Cloud Status
										Element:li
										Element:a
											Community
										Element:li
										Element:a
											Customers & Use Cases
										Element:li
										Element:a
											Documentation
										Element:li
										Element:a
											Elastic{ON} Events
										Element:li
										Element:a
											Forums
										Element:li
										Element:a
											Meetups
										Element:li
										Element:a
											Subscriptions
										Element:li
										Element:a
											Support Portal
										Element:li
										Element:a
											Videos & Webinars
										Element:li
										Element:a
											Training
										Element:h3
										Element:a
											About >
										Element:ul
										Element:li
										Element:a
											Careers/Jobs
										Element:li
										Element:a
											Contact
										Element:li
										Element:a
											Leadership
										Element:li
										Element:a
											Partners
										Element:li
										Element:a
											Press
										Element:h3
											Language
										Element:ul
										Element:li
										Element:a
											English
										Element:li
										Element:a
											Français
										Element:li
										Element:a
											Deutsch
										Element:li
										Element:a
											日本語
										Element:li
										Element:a
											한국어
										Element:p
											FOLLOW US
										Element:ul
										Element:li
										Element:a
										Element:li
										Element:a
										Element:li
										Element:a
										Element:li
										Element:a
										Element:li
										Element:a
										Element:ul
										Element:li
										Element:a
											Trademarks
										Element:li
										Element:a
											Terms of Use
										Element:li
										Element:a
											Privacy
										Element:li
										Element:a
											Cookie Policy
										Element:li
										Element:a
											Brand
										Element:a
										Element:img
										Element:p
											© 2017. All Rights Reserved - Elasticsearch
										Element:p
											Elasticsearch is a trademark of Elasticsearch BV, registered in the U.S. and in other countries
										Element:p
											Apache, Apache Lucene, Apache Hadoop, Hadoop, HDFS and the yellow elephant logo are trademarks of the
										Element:a
											Apache Software Foundation
											in the United States and/or other countries.
